########### These MUST be filled in for a storm configuration
 storm.zookeeper.servers:
     - "cn04"

 storm.zookeeper.root: "/jstorm"
 
 #nimbus.host is being used by $JSTORM_HOME/bin/start.sh
 #it only support IP, please don't set hostname
 # For example 
 # nimbus.host: "10.132.168.10, 10.132.168.45"
 #nimbus.host: "localhost"
 
# %JSTORM_HOME% is the jstorm home directory
 storm.local.dir: "%JSTORM_HOME%/data"
 
 java.library.path: "/usr/local/lib:/opt/local/lib:/usr/lib"

 worker.gc.childopts: "-Xms2048m -Xmx2048m -XX:SurvivorRatio=4 -XX:+UseConcMarkSweepGC  -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:CMSFullGCsBeforeCompaction=5 -XX:+HeapDumpOnOutOfMemoryError -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseCMSCompactAtFullCollection -XX:CMSMaxAbortablePrecleanTime=5000 "
 supervisor.childopts: " -Xms1024m -Xmx1024m -Xmn128m -XX:PermSize=128m -XX:+UseConcMarkSweepGC  -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:CMSFullGCsBeforeCompaction=5 -XX:+HeapDumpOnOutOfMemoryError  -XX:+UseCMSCompactAtFullCollection -XX:CMSMaxAbortablePrecleanTime=5000 "
 nimbus.childopts: " -Xms4g -Xmx4g -Xmn1536m -XX:PermSize=256m  -XX:SurvivorRatio=4 -XX:+UseConcMarkSweepGC  -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:CMSFullGCsBeforeCompaction=5 -XX:+HeapDumpOnOutOfMemoryError  -XX:+UseCMSCompactAtFullCollection -XX:CMSMaxAbortablePrecleanTime=5000 "

# if supervisor.slots.ports is null, 
# the port list will be generated by cpu cores and system memory size 
# for example, if there are 24 cpu cores and supervisor.slots.port.cpu.weight is 1.2
# then there are 24/1.2 ports for cpu, 
# there are system_physical_memory_size/worker.memory.size ports for memory 
# The final port number is min(cpu_ports, memory_port)
 supervisor.slots.ports.base: 6800
 supervisor.slots.port.cpu.weight: 1
 supervisor.slots.ports: null
 supervisor.slots.ports:
    - 6800
    - 6801
    - 6802
    - 6803

# Default disable user-define classloader
# If there are jar conflict between jstorm and application, 
# please enable it 
 topology.enable.classloader: false

# enable supervisor use cgroup to make resource isolation
# Before enable it, you should make sure:
# 	1. Linux version (>= 2.6.18)
# 	2. Have installed cgroup (check the file's existence:/proc/cgroups)
#	3. You should start your supervisor on root
# You can get more about cgroup:
#   http://t.cn/8s7nexU
 supervisor.enable.cgroup: false


### Netty will send multiple messages in one batch  
### Setting true will improve throughput, but more latency
 storm.messaging.netty.transfer.async.batch: false
 storm.messaging.netty.sync.mode: false

### if this setting  is true, it will use disruptor as internal queue, which size is limited
### otherwise, it will use LinkedBlockingDeque as internal queue , which size is unlimited
### generally when this setting is true, the topology will be more stable,
### but when there is a data loop flow, for example A -> B -> C -> A
### and the data flow occur blocking, please set this as false
 topology.buffer.size.limited: true
 storm.messaging.netty.flush.check.interval.ms: 1
 
### default worker memory size, unit is byte
 worker.memory.size: 2147483648

# Metrics Monitor
# topology.performance.metrics: it is the switch flag for performance 
# purpose. When it is disabled, the data of timer and histogram metrics 
# will not be collected.
# topology.alimonitor.metrics.post: If it is disable, metrics data
# will only be printed to log. If it is enabled, the metrics data will be
# posted to alimonitor besides printing to log.
 topology.performance.metrics: true
 topology.alimonitor.metrics.post: false

# UI MultiCluster
# Following is an example of multicluster UI configuration
# ui.clusters:
#     - {
#         name: "jstorm",
#         zkRoot: "/jstorm",
#         zkServers:
#             [ "localhost"],
#         zkPort: 2181,
#       }

 storm.local.dir: "/scratch/jstorm"

 # Intranode communications
 storm.messaging.intranode.base_file: "/scratch/jstorm_mapped"